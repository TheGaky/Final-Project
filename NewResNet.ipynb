{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d510a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "epochs = 2000\n",
    "image_size = (360, 640)\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d81bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels_arr, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.DataFrame(labels_arr)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = torch.tensor(int(self.img_labels.iloc[idx, 1]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image.float())\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "def create_dataset(folder, label):\n",
    "    files = os.listdir(folder)\n",
    "    for i in files:\n",
    "        if i =='.DS_Store':\n",
    "            files.remove(i)\n",
    "    files = np.array(files)\n",
    "    labels_arr = np.zeros(len(files), dtype=np.uint8)\n",
    "    labels_arr.fill(label)\n",
    "    labels_arr = np.column_stack((files, labels_arr))\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize(image_size)])\n",
    "    dataset = CustomImageDataset(labels_arr, folder, transform=transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ff4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850\n"
     ]
    }
   ],
   "source": [
    "#pure train datasets\n",
    "dataset_on = create_dataset(\"/Users/gaky/Desktop/efir/on for use/on\", int(0))\n",
    "dataset_low = create_dataset(\"/Users/gaky/Desktop/efir/on for use/final low on\", int(0))\n",
    "dataset_off = create_dataset(\"/Users/gaky/Desktop/efir/off for use/off mix\", int(1))\n",
    "dataset_night = create_dataset(\"/Users/gaky/Desktop/efir/off for use/off night\", int(2))\n",
    "\n",
    "\n",
    "#agmented train datasets\n",
    "dataset_off_changed = create_dataset(\"/Users/gaky/Desktop/efir/off for use/off changed\", int(1))\n",
    "dataset_off_blur = create_dataset(\"/Users/gaky/Desktop/efir/off for use/off blur\", int(1))\n",
    "\n",
    "\n",
    "#validation datasets\n",
    "dataset_off_val = create_dataset(\"/Users/gaky/Desktop/efir/off for use/validation off mix\", int(1))\n",
    "dataset_low_val = create_dataset(\"/Users/gaky/Desktop/efir/on for use/low valid\", int(0))\n",
    "dataset_on_val = create_dataset(\"/Users/gaky/Desktop/efir/on for use/validation on\", int(0))\n",
    "\n",
    "train_dataset = ConcatDataset([dataset_on, dataset_low, dataset_off, dataset_night, dataset_off_blur])\n",
    "print(len(train_dataset))\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader_val_off = DataLoader(dataset_off_val, batch_size=len(dataset_off_val), shuffle=False)\n",
    "dataloader_low_val = DataLoader(dataset_low_val, batch_size=len(dataset_low_val), shuffle=False)\n",
    "dataloader_on_val = DataLoader(dataset_on_val, batch_size=len(dataset_on_val), shuffle=False)\n",
    "\n",
    "dataloader_off = DataLoader(dataset_off, batch_size=len(dataset_off), shuffle=False)\n",
    "dataloader_low = DataLoader(dataset_low, batch_size=len(dataset_low), shuffle=False)\n",
    "dataloader_on = DataLoader(dataset_on, batch_size=len(dataset_on), shuffle=False)\n",
    "dataloader_night = DataLoader(dataset_night, batch_size=len(dataset_night), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b94926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "       \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "        x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        print(x.shape)\n",
    "        print(identity.shape)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff9c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3,8,36,3], 3, 3).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.01, momentum = 0.9)\n",
    "#optim = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63021f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch):\n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save(\"/Users/gaky/Desktop/efir/Models/strange model/\"+ str(epoch) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46bed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model2(epoch):\n",
    "    torch.save(model.state_dict(), \"/Users/gaky/Desktop/efir/Models/strange model2/\"+ str(epoch) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d698dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, name):\n",
    "    with torch.no_grad():\n",
    "        dataset = iter(dataloader)\n",
    "        x, y = next(dataset)\n",
    "        \n",
    "        x = x/255.\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.eval()\n",
    "        out = model(x.float())\n",
    "        cat = torch.argmax(out, dim=1)\n",
    "        \n",
    "        if name == \"off_val\":\n",
    "            for i in range(len(cat)):\n",
    "                if cat[i] == 2:\n",
    "                    cat[i] = 1\n",
    "\n",
    "        accuracy = (cat == y).float().mean()\n",
    "        print(accuracy, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d76f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(dataloader, name):\n",
    "    with torch.no_grad():\n",
    "        dick = []\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "        \n",
    "            x = x/255.\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            model.eval()\n",
    "            out = model(x.float())\n",
    "            cat = torch.argmax(out, dim=1)\n",
    "\n",
    "\n",
    "            if name == \"off\":\n",
    "                for i in range(len(cat)):\n",
    "                    if cat[i] == 2:\n",
    "                        cat[i] = 1\n",
    "            \n",
    "            accuracy = (cat == y).float()\n",
    "            dick.append(accuracy.mean())\n",
    "        print(np.mean(dick), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54342a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(1.0511, grad_fn=<MeanBackward0>)\n",
      "0 1 tensor(0.1308, grad_fn=<MeanBackward0>)\n",
      "0 2 tensor(0.3343, grad_fn=<MeanBackward0>)\n",
      "0 3 tensor(0.0895, grad_fn=<MeanBackward0>)\n",
      "0 4 tensor(0.9416, grad_fn=<MeanBackward0>)\n",
      "0 5 tensor(0.1095, grad_fn=<MeanBackward0>)\n",
      "0 6 tensor(0.5079, grad_fn=<MeanBackward0>)\n",
      "0 7 tensor(0.1917, grad_fn=<MeanBackward0>)\n",
      "0 8 tensor(0.3785, grad_fn=<MeanBackward0>)\n",
      "0 9 tensor(0.3109, grad_fn=<MeanBackward0>)\n",
      "0 10 tensor(0.2796, grad_fn=<MeanBackward0>)\n",
      "0 11 tensor(0.5198, grad_fn=<MeanBackward0>)\n",
      "0 12 tensor(0.4670, grad_fn=<MeanBackward0>)\n",
      "0 13 tensor(0.4765, grad_fn=<MeanBackward0>)\n",
      "0 14 tensor(0.4806, grad_fn=<MeanBackward0>)\n",
      "0 15 tensor(0.3925, grad_fn=<MeanBackward0>)\n",
      "0 16 tensor(0.5978, grad_fn=<MeanBackward0>)\n",
      "0 17 tensor(0.4283, grad_fn=<MeanBackward0>)\n",
      "0 18 tensor(0.4230, grad_fn=<MeanBackward0>)\n",
      "0 19 tensor(0.2079, grad_fn=<MeanBackward0>)\n",
      "0 20 tensor(0.5202, grad_fn=<MeanBackward0>)\n",
      "0 21 tensor(0.7179, grad_fn=<MeanBackward0>)\n",
      "0 22 tensor(0.2463, grad_fn=<MeanBackward0>)\n",
      "0 23 tensor(0.6765, grad_fn=<MeanBackward0>)\n",
      "0 24 tensor(0.3546, grad_fn=<MeanBackward0>)\n",
      "0 25 tensor(0.3500, grad_fn=<MeanBackward0>)\n",
      "0 26 tensor(0.3580, grad_fn=<MeanBackward0>)\n",
      "0 27 tensor(0.1051, grad_fn=<MeanBackward0>)\n",
      "0 28 tensor(0.6748, grad_fn=<MeanBackward0>)\n",
      "0 29 tensor(0.3738, grad_fn=<MeanBackward0>)\n",
      "0 30 tensor(1.0893, grad_fn=<MeanBackward0>)\n",
      "0 31 tensor(0.2435, grad_fn=<MeanBackward0>)\n",
      "0 32 tensor(0.2519, grad_fn=<MeanBackward0>)\n",
      "0 33 tensor(0.1888, grad_fn=<MeanBackward0>)\n",
      "0 34 tensor(0.1963, grad_fn=<MeanBackward0>)\n",
      "0 35 tensor(0.3426, grad_fn=<MeanBackward0>)\n",
      "0 36 tensor(0.2314, grad_fn=<MeanBackward0>)\n",
      "0 37 tensor(0.3968, grad_fn=<MeanBackward0>)\n",
      "0 38 tensor(0.7212, grad_fn=<MeanBackward0>)\n",
      "0 39 tensor(0.5117, grad_fn=<MeanBackward0>)\n",
      "0 40 tensor(0.9166, grad_fn=<MeanBackward0>)\n",
      "0 41 tensor(0.3275, grad_fn=<MeanBackward0>)\n",
      "0 42 tensor(0.1478, grad_fn=<MeanBackward0>)\n",
      "0 43 tensor(0.4232, grad_fn=<MeanBackward0>)\n",
      "0 44 tensor(0.1441, grad_fn=<MeanBackward0>)\n",
      "0 45 tensor(0.3464, grad_fn=<MeanBackward0>)\n",
      "0 46 tensor(0.6677, grad_fn=<MeanBackward0>)\n",
      "0 47 tensor(0.4994, grad_fn=<MeanBackward0>)\n",
      "0 48 tensor(0.1200, grad_fn=<MeanBackward0>)\n",
      "0 49 tensor(0.4321, grad_fn=<MeanBackward0>)\n",
      "0 50 tensor(0.1404, grad_fn=<MeanBackward0>)\n",
      "0 51 tensor(0.3215, grad_fn=<MeanBackward0>)\n",
      "0 52 tensor(0.1335, grad_fn=<MeanBackward0>)\n",
      "0 53 tensor(1.8900, grad_fn=<MeanBackward0>)\n",
      "4.042695760726929\n",
      "0.43295451984913264\n",
      "1 0 tensor(0.3488, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8525) off_val\n",
      "tensor(0.7429) low_val\n",
      "tensor(0.9688) on_val\n",
      "1 1 tensor(0.4049, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/45/wj5m3mk56b38wrkpv32mr0240000gn/T/ipykernel_50540/4268568516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for i, (x, y) in enumerate(dataloader_train):\n",
    "        x = x/255.\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.train()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        start = time.time()\n",
    "        \n",
    "        out = model(x.float())\n",
    "        \n",
    "        loss = loss_function(out, y.long())\n",
    "        loss_mean = loss.mean()\n",
    "        loss_mean.backward()\n",
    "        optim.step()\n",
    "\n",
    "        print(epoch, i, loss_mean)\n",
    "        \n",
    "        losses.append(loss.detach().item())\n",
    "        \n",
    "        if epoch % 1 == 0 and epoch != 0 and i == 0:\n",
    "            evaluate(dataloader_val_off, \"off_val\")\n",
    "            evaluate(dataloader_low_val, \"low_val\")\n",
    "            evaluate(dataloader_on_val, \"on_val\")\n",
    "            \n",
    "            #evaluate2(dataloader_on, \"on\")\n",
    "            #evaluate2(dataloader_off, \"off\")\n",
    "            #evaluate2(dataloader_low, \"low\")\n",
    "            \n",
    "            save_model2(epoch)\n",
    "            #evaluate(dataloader_off, \"off\")\n",
    "            #evaluate(dataloader_low, \"low\")\n",
    "            #evaluate(dataloader_on, \"on\")\n",
    "            #evaluate(dataloader_night, \"night\")\n",
    "            \n",
    "    stop = time.time()\n",
    "    print(stop - start)\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6bd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
